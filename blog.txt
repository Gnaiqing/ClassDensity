概述：广义的分类有两种含义：一种含义是有的学监督习过程，另一种是无监督的学习过程。通常前者称为分类，后者称为聚类，后文中提到的分类都是指有指导的学习过程。给定分类体系，将文本集中的每个文本分到某个或者某几个类别中，这个过程称为文本分类。将文本集合分组成多个类或簇，使得在同一个簇中的文本内容具有较高的相似度，而不同簇中的文本内容差别较大，这个过程称为文本聚类。
文本分类：文本分类过程可以分为手工分类和自动分类。前者最著名的实例是雅虎的网页分类体系，是由专家定义了分类体系，然后人工将网页分类。这种方法需要大量人力，现实中已经采用的很少了。自动文本分类算法大致可以分为两类：知识工程方法和机器学习方法。知识工程方法指的是由专家为每个类别定义一些规则，这些规则代表了这个类别的特征，自动把符合规则的文档划分到相应的类别中。上个世纪九十年代之后，机器学习方法成为主导。机器学习方法与知识工程方法相比，能够达到相似的精确度，但是减少了大量的人工参与。我们下面主要介绍基于机器学习方法的文本分类。
文本分类的步骤：典型的文本分类过程可以分为三个步骤：
1.文本表示：这一过程的目的是把文本表示成分类器能够处理的形式。最常用的方法是向量空间模型，即把文本集表示成词－文档矩阵，矩阵中每个元素代表了一个词在相应文档中的权重。选取哪些词来代表一个文本，这个过程称为特征选择。常见的特征选择方法有文档频率、信息增益、互信息、期望交叉熵等等。为了降低分类过程中的计算量，常常还需要进行降维处理，比如LSI。?
2.分类器构建：这一步骤的目的是选择或设计构建分类器的方法。没有一种通用的方法可以适用所有情况。不同的方法有各自的优缺点和适用条件，要根据问题的特点来选择一个分类器。我们会在后面专门讲述常用的方法。选定方法之后，在训练集上为每个类别构建分类器，然后把分类器应用于测试集上，得到分类结果。?
3.效果评估：在分类过程完成之后，需要对分类效果进行评估。评估过程应用于测试集（而不是训练集）上的文本分类结果，常用的评估标准由信息检索领域继承而来，包括查全率、查准率、F1值等等。F1值为查全率和查准率的调和平均数。?相对于最简单的训练集－测试集评估方法而言，还有一种称为k-fold cross validation的方法，即把所有标记的数据划分成k个子集，对于每个子集，把这个子集当作训练集，把其余子集作为测试集；这样执行k次，取各次评估结果的平均值作为最后的评估结果。
Rocchio方法：每一类确定一个中心点，计算待分类的文档与各类代表元间的距离，并作为判定是否属于该类的判据。Rocchio方法的特点是容易实现，效率高。缺点是受文本集分布的影响，比如计算出的中心点可能落在相应的类别之外。
朴素贝叶斯方法：将概率论模型应用于文档自动分类，是一种简单有效的分类方法。使用贝叶斯公式，通过先验概率和类别的条件概率来估计文档对某一类别的后验概率，以此实现对此文档所属类别的判断。
K近邻(K-Nearest Neightbers, KNN)方法：从训练集中找出与待分类文档最近的k个邻居（文档），根据这k个邻居的类别来决定待分类文档的类别。KNN方法的优点是不需要特征选取和训练，很容易处理类别数目多的情况，缺点之一是空间复杂度高。KNN方法得到的分类器是非线性分类器。
支持向量机（SVM）方法：对于某个类别，找出一个分类面，使得这个类别的正例和反例落在这个分类面的两侧，而且这个分类面满足：到最近的正例和反例的距离相等，而且是所有分类面中与正例（或反例）距离最大的一个分类面。SVM方法的优点是使用很少的训练集，计算量小；缺点是太依赖于分类面附近的正例和反例的位置，具有较大的偏执。
文本聚类：文本聚类有很多应用，比如提高信息检索系统的查全率，导航/组织电子资源，等等。根据聚成的簇的特点，聚类技术通常分为层次聚类和划分聚类。前者比较典型的例子是凝聚层次聚类算法，后者的典型例子是k-means算法。近年来出现了一些新的聚类算法，它们基于不同的理论或技术，比如图论，模糊集理论，神经网络以及核技术等等。
文本聚类的步骤：与文本分类类似，文本聚类过程可以分为3个步骤：
1.文本表示：把文档表示成聚类算法可以处理的形式。所采用的技术请参见文本分类部分。?
2.聚类算法选择或设计：算法的选择，往往伴随着相似度计算方法的选择。在文本挖掘中，最常用的相似度计算方法是余弦相似度。聚类算法有很多种，但是没有一个通用的算法可以解决所有的聚类问题。因此，需要认真研究要解决的问题的特点，以选择合适的算法。后面会有对各种文本聚类算法的介绍。?
3.聚类评估：因为没有训练文档集合，所以评测聚类效果是比较困难的。 常用的方法是： 选择人工已经分好类或者做好标记的文档集合作为测试集合，聚类结束后，将聚类结果与已有的人工分类结果进行比较。常用评测指标也是查全率、查准率及F1值。
层次聚类方法：层次聚类可以分为两种：凝聚层次聚类和划分层次聚类。凝聚方法把每个文本作为一个初始簇，经过不断的合并过程，最后成为一个簇。划分方法的过程正好与之相反。划分方法在现实中采用较少。层次聚类可以得到层次化的聚类结果，但是计算复杂度比较高，不能处理大量的文档。近年来出现了新的层次聚类算法。
划分方法：k-means算法是最常见的划分方法。给定簇的个数k，选定k个文本分别作为k个初始簇，将其他的文本加入最近的簇中，并更新簇的中心点，然后再根据新的中心点对文本重新划分；当簇不再变化时或经过一定次数的迭代之后，算法停止。k-means算法复杂度低，而且容易实现，但是对例外和噪声文本比较敏感。另外一个问题是，没有一个好的办法确定k的取值。
基于密度的方法：为了发现任意形状的聚类结果，提出了基于密度的方法。这类方法将簇看作是数据空间中被低密度区域分割开的高密度区域。常见的基于密度的方法有DBSCAN, OPTICS, DENCLUE等等。
神经网络方法：神经网络方法将每个簇描述为一个标本，标本作为聚类的"原型"，不一定对应一个特定的数据,根据某些距离度量，新的对象被分配到与其最相似的簇中。比较著名的神经网络聚类算法有:竞争学习和自组织特征映射。神经网络的聚类方法需要较长的处理时间和复杂的数据复杂性，所以不适用于大型数据的聚类。
