文本分类及朴素贝叶斯方法：迄今为止，本书主要讨论的是 ad hoc 检索过程，其中用户的信息需求是瞬时的、短暂的，而用户则通过向搜索引擎提交一个或者多个查询的方式来处理需求。但是，很多用户拥有固定的信息需求。为此，许多系统都支持固定查询，它和其他类型的查询的唯一不同之处在于：它会在一个不断增量式更新的文档集上得到定期的处理。为了达到较高的召回率，固定查询本身也要随时间不断改进从而逐渐变得越来越复杂。不失一般性，并且为了获得固定查询所属问题的空间范围，下面我们引入分类这个一般性的概念。给定一系列类别，分类是指将给定对象归入一个或者多个类别的过程。基于固定查询进行分类也称为信息路由或者过滤。一个类别不一定就像前面提到的固定查询那样关注范围那么窄。通常来说，类别往往是一个更一般的主题领域。这种更一般意义上的类别往往也称为主题，面向文本的分类任务则称为文本分类或主题发现。尽管固定查询和主题在具体程度上有所不同，但是解决信息路由、过滤和文本分类的方法在本质上是一致的。因此，本章及以后章节都会将信息路由和过滤归入到文本分类任务。分类是一个极其一般性的概念，在信息检索及其他领域都有很多应用。索引构建过程中几个必要的预处理问题：文档编码的识别、分词（两个字母之间的空格是否代表词之间的间隔？）、真实的大小写处理及文档语言类型的判定。最后，ad hoc 信息检索中的排序函数也可以基于文档分类器来构建。实际上，当今大部分检索系统中的多个部件中都使用了某种形式的分类器。本书中主要以文本分类为例来介绍分类任务。分类并不一定要使用计算机。通常来说，很多分类任务都是通过人工来完成的。图书馆管理员将美国国会图书馆分类号分配给每本图书。但是，人工分类的方法一旦要规模化则开销会很大。可以采用另外一种思路，即直接利用固定查询将其想象成某种规则来进行分类，这些规则一般由人来编写，有时规则即等价于布尔表达式。这些规则通过关键词的某种组合来代表一个类别。人工编写的规则具有很好的扩展性，但是创建和长时间维护这些规则需要很高的人力成本。高水平的专业人士（比如，一个善于撰写正则表达式规则的领域专家）能够建立很好的规则集，这些规则集能够与我们马上要介绍的自动分类器的精度相当甚至超过后者，但是，找到具有这种专长的人才非常困难。除了手工分类和人工编写规则之外，还存在第三种文本分类的方法，即基于机器学习的方法。在接下来的章节中，我们主要关注这种方法。在机器学习中，规则（更通用的说法是分类决策准则）是从训练数据中自动学习得到的。当学习方法基于统计时，这种方法也称为统计文本分类。在统计文本分类中，对于每个类别我们需要一些好的文档样例（或者称为训练文档）。由于需要人来标注训练文档，所以对人工分类的需求仍然存在。这里的标注指的是对每篇文档赋予类别标签的过程。但是可以证明，标注工作会比撰写规则更容易。几乎每个人都可以浏览一篇文档然后确定它是否和 China 相关。有时，人们的标注过程还会隐含在现有的工作流程中（即此时并不需要人们进行特意的、显式的标注）。本章首先将给出文本分类问题的一般性介绍，其中包括它的一个形式化定义，然后介绍一种具体的简单高效的分类方法―朴素贝叶斯方法。我们考察的所有分类方法都将文档表示在高维空间。为了提高这些方法的效率，通常要考虑进行空间降维。因此，一种称为特征选择的技术在文本分类中被普遍使用。13.6节主要介绍文本分类的评价。
基于向量空间模型的文本分类：在朴素贝叶斯分类当中，文档表示成词项序列或者一个布尔向量。本章将采用一种不同的文档表示方法。具体地，我们将采用向量空间模型来表示文档。向量空间模型将每篇文档表示成实数型分量所构成的向量，每个分量对应一个词项，并往往采用 tf-idf 权重来计算。本章主要介绍基于这种实数向量表示的文本分类方法。利用向量空间模型进行文本分类的思路主要基于邻近假设。邻近假设：同一类的文档会构成一个邻近区域，而不同类的邻近区域之间是互不重叠的。很多种分类任务，可以通过词的出现模式来区别不同的类别。文档集是否会映射成邻近区域取决于在文档表示中的很多选项，例如权重计算方法、停用词表等。如果选择了不合适的文档表示方法，那么邻近假设将不成立，此时基于向量空间的分类方法也不可能成功。基于同样的考虑，在进行文档表示时往往要考虑带权重的表示方法，基于长度归一化的 tf-idf 权重表示方法也会在这儿使用。无权重计算和无归一化的数字将不会在基于向量空间模型的分类方法中使用。本章将介绍两种基于向量空间模型的分类方法，它们分别是 Rocchio 方法和 kNN 方法。前者基于质心或原型将整个向量空间划分成多个区域。每个质心或原型代表一类，通常采用该类中所有文档向量的平均来计算。Rocchio 方法非常简单、时空消耗也小，但是当某类的内部文档并不近似分布在半径相近的球体之内时，其分类精度并不高。kNN 或 k近邻分类方法将k个最近邻文档所属的主类别赋给测试文档。kNN 不需要显式的训练过程，它可以直接使用未处理过的训练集进行分类。相对于其他分类方法，kNN 的分类效率较低。但如果训练集很大，kNN 在处理非球体型类别以及其他复杂的类别时优于 Rocchio 方法。线性分类器是指基于特征的简单线性组合就可以对文档进行分类的分类器，许多文本分类器都可以看成是线性分类器。这种分类器通过线性决策超平面将整个特征空间划分成多个区域，具体的划分细节将在后面详细介绍。基于偏差―方差折衷准则，更复杂的非线性分类模型并不会系统地优于线性模型。非线性模型需要在有限的训练数据上拟合出更多的参数，因此对于小规模的有噪音数据集则更有可能犯错误。当将二类分类器应用到多类问题上时，通常有两种任务，第一种任务称为单标签任务，该任务中要求每篇文档只能分到多个互斥类别当中的某一个类别中去。第二种任务称为多标签任务，即一篇文档可以分到任意数目的类别当中去。二类分类器能够解决多标签问题，通过组合也可以解决单标签问题。
支持向量机及文档机器学习方法：如何提高分类器的效果一直是机器学习研究中一个集中性话题，也因此产生了一系列的高效分类器，如支持向量机、提升式决策树、正则化logistic回归、神经网络和随机森林等。其中大部分，包括作为本章主要话题的支持向量机方法，已经成功地应用到很多信息检索问题特别是文本分类当中。SVM 是最大间隔分类器的一种，它是基于向量空间的机器学习方法，其目标是找到两个类别之间的一个决策边界，使之尽量远离训练集上的任意一点（当然一些离群点和噪音点可能不包括在内）。本章首先从二类线性可分问题出发，导出 SVM 分类器，然后将模型推广到非线性可分数据、多类问题及非线性模型，另外也将讨论一些 SVM 的性能。之后，我们将讨论在实际开发文本分类器时遇到的问题，包括什么时候用哪类分类器、如何在分类中融入领域文本特征等。最后，我们将介绍如何把分类中采用的机器学习技术应用到 ah hoc 检索中的文档排序中去。尽管有多个机器学习方法已经用于检索文档排序当中，但 SVM 的使用仍然占主导地位。虽然除了在小训练集情况下，或许 SVM 会占点优势之外，在其他情况下它并不一定会优于其他机器学习方法，但是它却表现出了目前最高的分类水平，并且在理论和经验方面更具有吸引力。
扁平聚类：聚类算法将一系列文档聚团成多个子集或簇，其目标是建立类内紧密、类间分散的多个簇。换句话说，聚类的结果要求簇内的文档之间要尽可能相似，而簇间的文档之间则要尽可能不相似。聚类是无监督学习的一种最普遍的形式。无监督也意味着不存在对文档进行类别标注的人类专家。聚类中，数据的分布和组成结构决定最后的类别归属。本章和下一章将介绍在无监督模式下寻找这种簇的算法。乍看起来，聚类和分类的区别并不大，毕竟这两种任务都会将文档分到不同的组中。然而，我们将会看到，这两个问题之间存在着本质的差异。分类是监督学习的一种形式，其目标是对人类赋予数据的类别差异进行学习或复制。而在以聚类为重要代表的无监督学习当中，并没有这样的人来对类别的差异进行引导。聚类算法的一个关键输入是距离计算方法。在文档聚类当中，距离计算方法往往采用欧氏距离。不同的距离计算方法会导致不同的聚类效果。因此，距离的计算方法是影响聚类结果的一个重要因素。扁平聚类算法会给出一系列扁平结构的簇，它们之间没有任何显式的结构来表明彼此的关联性。而层次聚类算法则会产生层次性的聚类结果。了解硬聚类和软聚类之间的差别也相当重要。硬聚类计算的是一个硬分配过程，即每篇文档仅仅属于一个簇。而软聚类算法的分配过程是软的，即一篇文档的分配结果是在所有簇上的一个分布。在软分配结果中，一篇文档可能对多个簇都具有隶属度。作为一种降维方法，隐性语义索引就是一个软聚类算法。本章首先通过一些应用来引入信息检索中的聚类算法，紧接着会给出聚类中需要解决的若干个问题的定义，进而讨论聚类结果的评价指标。然后将介绍两种聚类算法：K-均值算法和EM算法。前者是硬聚类算法，而后者是软聚类算法。由于K-均值算法简单高效，它或许是目前使用最广泛的扁平聚类算法。而 EM 是K-均值算法的一般化形式，可以应用到许多文档表示和文档分布中去。
层次聚类：扁平聚类具有概念简单、速度快的优点，但是同时也有很多缺点。上一章中介绍的算法返回的是一个无结构的扁平簇集合，它们需要预先定义簇的数目，并且聚类结果具有不确定性。与之不同的是，层次聚类则会输出一个具有层次结构的簇集合，因此能够比扁平聚类输出的无结构簇集合提供更丰富的信息。层次聚类不需要事先指定簇的数目，并且大部分用于信息检索中的层次聚类算法都是确定性算法。当然，层次聚类在获得这些好处的同时，其代价就是效率降低。最普遍的层次聚类算法的时间复杂度至少是文档数目的平方级，而前面提到的K-均值算法和EM算法的时间复杂度都是线性的。本章将首先介绍凝聚式层次聚类，然后将分别给出四种不同的凝聚式算法，它们分别采用了不同的相似度计算方法：单连接、全连接、组平均及质心相似度方法。本章还将讨论层次聚类的最优性条件、介绍自顶向下（也称为分裂式）的层次式聚类方法、介绍簇标签自动生成的问题，只要存在用户和聚类结果的交互，那么我们就必须解决这个问题。在信息检索中，扁平聚类和层次聚类的应用领域几乎没有差别。通常来说，当效率因素非常重要时，我们选择扁平聚类算法。而当扁平算法的问题（如结构信息不足、簇数目需要预先定义、聚类结果非确定性）需要加以考虑时，我们则采用层次算法。此外，有很多研究人员相信，层次方法产生的聚类结果会比扁平方法更好。然而，关于这一点目前还没有形成一致的结论。
矩阵分解及隐性语义索引：词项-文档矩阵的概念，即由 M 个词项和 N 篇文档组成的一个 M×N 的权重矩阵 C，矩阵的每行代表一个词项，每列代表一篇文档。即使对于一个中等规模的文档集来说，词项―文档矩阵可能都会有上万的行和列。我们首先给出了线性代数中的一类所谓矩阵分解的运算，然后我们将使用矩阵分解的某个具体形式来建立词项―文档矩阵的低秩逼近矩阵，接着考察该低秩逼近矩阵在索引和检索文档时的应用，这也就是人们常常提到的隐性语义索引技术。尽管隐性语义索引信息检索目前的评分和排名当中并不是一个非常重要的技术，但是它在某些领域的文档聚类当中仍然充满生命力。如何理解并发挥隐性语义索引的潜力仍然是一个活跃的研究领域。
